{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "### The Agent\n",
    "This class is a representing a reinforcement learner and provides some convenient functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    '''Class for a reinforcement learner.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    observations    :   tf.placeholder\n",
    "                        Input port for currently observed environment. Shape is (1, 4)\n",
    "    gradients   :   list\n",
    "                    Negative gradients for the 4 trainable variables of the fully connected network\n",
    "    grad_placeholders   :   list\n",
    "                            `tf.placeholder`s for each of the trainable variables. Must be fed during\n",
    "                            `train()`\n",
    "    training_step   :   tf.op\n",
    "                        Gradient application operation\n",
    "    '''\n",
    "\n",
    "    def __init__(self, learning_rate, **kwargs):\n",
    "        '''Respected kwargs are\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        steps   :   int\n",
    "                    Decay learning rate according to `exponential_decay` every `steps` steps\n",
    "        decay   :   decay factor for `exponential_decay`\n",
    "        learning_rate   :   base learning rate for `exponential_decay`\n",
    "        '''\n",
    "\n",
    "        ######################################\n",
    "        #  Create the dynamic learning rate  #\n",
    "        ######################################\n",
    "        step_counter       = tf.Variable(0, trainable=False, dtype=tf.int32, name='step_counter')\n",
    "        steps              = kwargs.get('steps', 100)\n",
    "        decay              = kwargs.get('decay', 0.8)\n",
    "        learning_rate      = tf.train.exponential_decay(learning_rate, step_counter, steps, decay)\n",
    "\n",
    "        ############################################################################################\n",
    "        #                                    Define the network                                    #\n",
    "        ############################################################################################\n",
    "        self.observations  = tf.placeholder(tf.float32, shape=[1, 4], name='observations')\n",
    "        hidden_layer       = fully_connected(self.observations, 8, with_activation=True,\n",
    "                                             activation=tf.nn.relu)\n",
    "        probability        = fully_connected(hidden_layer, 1, with_activation=True,\n",
    "                                             activation=tf.nn.sigmoid)\n",
    "        complementary      = tf.subtract(1.0, probability)\n",
    "        output             = tf.concat([probability, complementary], 1, name='action_probabilities')\n",
    "        log_likelihoods    = tf.log(output)\n",
    "        self.action        = tf.multinomial(log_likelihoods, num_samples=1)[0][0]\n",
    "        log_likelihood     = log_likelihoods[:, tf.to_int32(self.action)]\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        grads_and_vars = optimizer.compute_gradients(log_likelihood)\n",
    "        self.gradients = [grad * -1 for (grad, _) in grads_and_vars]\n",
    "\n",
    "        # Gradients must be fed for training\n",
    "        self.grad_placeholders = []\n",
    "        for i, gradient in enumerate(self.gradients):\n",
    "            self.grad_placeholders.append(tf.placeholder(tf.float32, gradient.shape,\n",
    "                                                         name='gradient_{}'.format(i)))\n",
    "        self.grad_dummies = [np.zeros(grad.shape) for grad in self.grad_placeholders]\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        self.training_step = optimizer.apply_gradients(zip(self.grad_placeholders, tvars),\n",
    "                                                       global_step=step_counter)\n",
    "\n",
    "\n",
    "    def get_action(self, observation, session):\n",
    "        '''Retrieve an action for a given set of observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation :   np.ndarray\n",
    "                        Array of shape (4,) or (1, 4), representing the current observation\n",
    "        session :   tf.Session\n",
    "                    Session to run ops in\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            0 or 1, depending on the action the network recommends\n",
    "        '''\n",
    "        # ensure input has 2 dims\n",
    "        if observation.ndim == 1:\n",
    "            observation = observation[np.newaxis, :]\n",
    "\n",
    "        feed_dict = {self.observations: observation}\n",
    "        # we don't actually need the gradients\n",
    "        feed_dict.update({p: grad for (p, grad) in zip(self.grad_placeholders, self.grad_dummies)})\n",
    "\n",
    "        return session.run([self.action] + self.gradients, feed_dict=feed_dict)\n",
    "\n",
    "    def train(self, discounted_gradients, session):\n",
    "        '''Apply discounted gradients computed over one episode.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        discounted_gradients    :   list\n",
    "                                    List of np.ndarrays with modified gradients for each of the 4\n",
    "                                    trainable variables\n",
    "        session :   tf.Session\n",
    "                    Session to run ops in\n",
    "        '''\n",
    "        feed_dict = {self.observations: np.zeros((1, 4), np.float32)}\n",
    "        feed_dict.update({p: grad for (p, grad) in zip(self.grad_placeholders, discounted_gradients)})\n",
    "\n",
    "        session.run([self.training_step], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected FFNN Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_n = 0\n",
    "def fully_connected(input, n_out, with_activation=False, activation=tf.nn.tanh,\n",
    "        use_bias=True):\n",
    "    '''Create a fully connected layer with fixed activation function and variable\n",
    "    initialisation. The activation function is ``tf.nn.tanh`` and variables are\n",
    "    initialised from a truncated normal distribution with an stddev of 0.1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input   :   tf.Variable\n",
    "                Input to the layer\n",
    "    n_out   :   int\n",
    "                Number of neurons in the layer\n",
    "    with_activation :   bool\n",
    "                        Return activation or drive (useful when planning to use\n",
    "                        ``softmax_cross_entropy_with_logits`` which requires\n",
    "                        unscaled logits)\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.Variable\n",
    "            The variable representing the layer activation\n",
    "    '''\n",
    "    global fc_n\n",
    "    fc_n += 1\n",
    "    with tf.variable_scope('fully%d' % fc_n):\n",
    "        (fan_in, fan_out) = (input.shape[-1].value, n_out)\n",
    "        if activation == tf.nn.tanh:\n",
    "            init_W = tf.random_normal_initializer(stddev=fan_in ** (-0.5))\n",
    "        elif activation == tf.nn.relu:\n",
    "            init_W = tf.random_normal_initializer(stddev=2 / fan_in)\n",
    "        else:\n",
    "            init_W = tf.random_normal_initializer()\n",
    "        init_b = tf.constant_initializer(0.1)\n",
    "        W = tf.get_variable(\n",
    "                'weights',\n",
    "                initializer=init_W,\n",
    "                shape=(input.shape[-1], n_out), # the last dim of the input\n",
    "               dtype=tf.float32                 # is the 1st dim of the weights\n",
    "            )\n",
    "        if use_bias:\n",
    "            bias = tf.get_variable('bias', initializer=init_b, shape=(n_out,))\n",
    "        if use_bias:\n",
    "            drive = tf.matmul(input, W) + bias\n",
    "        else:\n",
    "            drive = tf.matmul(input, W)\n",
    "        if with_activation:\n",
    "            return activation(drive)\n",
    "        else:\n",
    "            return drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discounted Rewards and Gradients\n",
    "These two functions will be used to compute the discounted rewards and based on those weigh the gradients accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_rewards(rewards_per_time, discount_factor):\n",
    "    '''Calculate the discounted rewards over a time series of rewards.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rewards_per_time    :   list or np.ndarray\n",
    "                            List of rewards observed for each time step\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Discounted rewards\n",
    "\n",
    "    '''\n",
    "    if not isinstance(rewards_per_time, np.ndarray):\n",
    "        rewards_per_time = np.array(rewards_per_time)\n",
    "\n",
    "    T = len(rewards_per_time)\n",
    "    # create vector with all elems set to factor and power it with [0,...,T-1]\n",
    "    factors = np.power(np.full((T,), discount_factor, np.float32), np.arange(T))\n",
    "    discounted_rewards = [np.dot(rewards_per_time[t:], factors[:T-t]) for t in range(T)]\n",
    "    mu, std = np.mean(discounted_rewards), np.std(discounted_rewards)\n",
    "    discounted_rewards = ((discounted_rewards - mu) / std)\n",
    "    return discounted_rewards\n",
    "\n",
    "\n",
    "def discounted_gradients(grads, discounted_rewards):\n",
    "    '''Discount gradients by multiplying with rewards\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    grads   :   list\n",
    "                Raw gradients\n",
    "    discounted_rewards  :   list or np.ndarray\n",
    "                            Reward factors as returned by `discounted_rewards()`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Discounted gradients\n",
    "\n",
    "    '''\n",
    "    discounted_gradients = []\n",
    "    # each time step is a list of arrays, so multiply each of those with the time step's discount\n",
    "    # factor'\n",
    "    for t in range(len(grads)):\n",
    "        discounted_gradients.append([g * discounted_rewards[t] for g in grads[t]])\n",
    "\n",
    "    return discounted_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model\n",
    "### Define the parameters accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes      = 1000  # Number of episodes\n",
    "iterations    = 200   # Number of steps per episode\n",
    "render_step   = 1000  # Render frame every r steps\n",
    "batch_size    = 1     # Average over several episodes\n",
    "learning_rate = 0.01  # Learning rate for Adam\n",
    "gamma         = 0.95  # Discount factor\n",
    "plot          = True  # Display a dynamic plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a little bar thingy for terminal peepz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_string(reward, iters, width=100):\n",
    "    '''Create a fun bar to visualise learner performance'''\n",
    "\n",
    "    done_bar = int(width * reward / iters) * '█'\n",
    "    spaces = (width - len(done_bar)) * ' '\n",
    "    return 'Cumulative reward: [{}{}]'.format(done_bar, spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVGEoiqIoofh/5j/Yt0bb3n0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a1cd860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "env.spec.max_episode_steps = iterations\n",
    "summed_gradient_buffer     = []\n",
    "\n",
    "if plot:\n",
    "    from matplotlib import pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    axes = fig.add_subplot(111)\n",
    "    graph, = axes.plot([], [])\n",
    "    axes.set_title('Amount of reward recevied over time')\n",
    "    axes.set_xlabel('iteration steps')\n",
    "    axes.set_ylabel('reward')\n",
    "    #plt.ion()\n",
    "    #plt.show()\n",
    "\n",
    "agent = Agent(learning_rate, steps=episodes // 5)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        gradient_buffer = []\n",
    "        summed_gradient_buffer = []\n",
    "        reward_buffer   = []\n",
    "        observation     = env.reset()\n",
    "        step_count      = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            act, *grads = agent.get_action(observation, session)\n",
    "\n",
    "            if episode * step_count % render_step == 0:\n",
    "                env.render()\n",
    "            step_count += 1\n",
    "\n",
    "            observation, reward, done, info = env.step(act)\n",
    "            reward_buffer.append(reward)\n",
    "            gradient_buffer.append(grads)\n",
    "\n",
    "            if done:\n",
    "                # print(progress_string(len(reward_buffer), iterations))\n",
    "                if plot:\n",
    "                    graph.set_xdata(np.append(graph.get_xdata(), episode * episodes + step_count))\n",
    "                    graph.set_ydata(np.append(graph.get_ydata(), len(reward_buffer)))\n",
    "                    axes.relim()\n",
    "                    axes.autoscale_view()\n",
    "                    #plt.draw()\n",
    "                    #plt.pause(0.01)\n",
    "\n",
    "\n",
    "        ##################\n",
    "        #  Episode done  #\n",
    "        ##################\n",
    "        rewards      = discounted_rewards(reward_buffer, gamma)\n",
    "        gradients    = discounted_gradients(gradient_buffer, rewards)\n",
    "        gradient_sum = np.sum(np.array(gradients), 0)\n",
    "        summed_gradient_buffer.append(gradient_sum)\n",
    "        if (episode + 1) % batch_size == 0:\n",
    "            for g in summed_gradient_buffer:\n",
    "                agent.train(g, session)\n",
    "            \n",
    "    if plot:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
