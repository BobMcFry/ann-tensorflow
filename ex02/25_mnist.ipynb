{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 2\n",
    "## Exercise 1 + 2 + 3\n",
    "First we adding some imports that we are going to use define the provided functions of `mnist-helper.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from tensorflow import truncated_normal_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST():\n",
    "    def __init__(self, directory):\n",
    "        self._directory = directory\n",
    "        \n",
    "        self._training_data = self._load_binaries(\"train-images-idx3-ubyte\")\n",
    "        self._training_labels = self._load_binaries(\"train-labels-idx1-ubyte\")\n",
    "        self._test_data = self._load_binaries(\"t10k-images-idx3-ubyte\")\n",
    "        self._test_labels = self._load_binaries(\"t10k-labels-idx1-ubyte\")\n",
    "        \n",
    "        np.random.seed(0)\n",
    "        samples_n = self._training_labels.shape[0]\n",
    "        random_indices = np.random.choice(samples_n, samples_n // 10, replace = False)\n",
    "        np.random.seed()\n",
    "        \n",
    "        self._validation_data = self._training_data[random_indices]\n",
    "        self._validation_labels = self._training_labels[random_indices]\n",
    "        self._training_data = np.delete(self._training_data, random_indices, axis = 0)\n",
    "        self._training_labels = np.delete(self._training_labels, random_indices)\n",
    "    \n",
    "    def _load_binaries(self, file_name):\n",
    "        path = os.path.join(self._directory, file_name)\n",
    "        \n",
    "        with open(path, 'rb') as fd:\n",
    "            check, items_n = struct.unpack(\">ii\", fd.read(8))\n",
    "\n",
    "            if \"images\" in file_name and check == 2051:\n",
    "                height, width = struct.unpack(\">II\", fd.read(8))\n",
    "                images = np.fromfile(fd, dtype = 'uint8')\n",
    "                return np.reshape(images, (items_n, height, width))\n",
    "            elif \"labels\" in file_name and check == 2049:\n",
    "                return np.fromfile(fd, dtype = 'uint8')\n",
    "            else:\n",
    "                raise ValueError(\"Not a MNIST file: \" + path)\n",
    "    \n",
    "    \n",
    "    def get_training_batch(self, batch_size):\n",
    "        return self._get_batch(self._training_data, self._training_labels, batch_size)\n",
    "    \n",
    "    def get_validation_batch(self, batch_size):\n",
    "        return self._get_batch(self._validation_data, self._validation_labels, batch_size)\n",
    "    \n",
    "    def get_test_batch(self, batch_size):\n",
    "        return self._get_batch(self._test_data, self._test_labels, batch_size)\n",
    "    \n",
    "    def _get_batch(self, data, labels, batch_size):\n",
    "        samples_n = labels.shape[0]\n",
    "        if batch_size <= 0:\n",
    "            batch_size = samples_n\n",
    "        \n",
    "        random_indices = np.random.choice(samples_n, samples_n, replace = False)\n",
    "        data = data[random_indices]\n",
    "        labels = labels[random_indices]\n",
    "        for i in range(samples_n // batch_size):\n",
    "            on = i * batch_size\n",
    "            off = on + batch_size\n",
    "            yield data[on:off], labels[on:off]\n",
    "    \n",
    "    \n",
    "    def get_sizes(self):\n",
    "        training_samples_n = self._training_labels.shape[0]\n",
    "        validation_samples_n = self._validation_labels.shape[0]\n",
    "        test_samples_n = self._test_labels.shape[0]\n",
    "        return training_samples_n, validation_samples_n, test_samples_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Here we are inspecting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist_digits(*digits_labels):\n",
    "    num = len(digits_labels)\n",
    "    rows = int(sqrt(num))\n",
    "    cols = int(num / rows + 0.5)\n",
    "    f, axarr = plt.subplots(rows, cols)\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            ax = axarr[row][col]\n",
    "            index = row * rows + col\n",
    "            ax.imshow(digits_labels[index][0],\n",
    "                    cmap='gray')\n",
    "            ax.set_title(digits_labels[index][1], x=-0.1,y=0.5)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "    return f\n",
    "\n",
    "# Create data loader\n",
    "mnist = MNIST(\".\")\n",
    "\n",
    "# Get training data for inspection.\n",
    "train_imgs = mnist._training_data\n",
    "train_labels = mnist._training_labels\n",
    "\n",
    "# Plot 20 exemplary images.\n",
    "f = plot_mnist_digits(*[(train_imgs[i, ...], train_labels[i]) for i in range(20)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Create the data flow graph (DFG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset graph in order to cope with multiple cell executions.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Weight matrix\n",
    "mean = 0.0\n",
    "std = 0.000002\n",
    "W = tf.get_variable('weights', initializer=truncated_normal_initializer(mean, std, seed=1), shape=[28 * 28, 10])\n",
    "\n",
    "# bias vector\n",
    "b = tf.get_variable('bias', initializer=tf.zeros_initializer(), shape=[10])\n",
    "\n",
    "# data vector\n",
    "x = tf.placeholder(tf.float32, [None, 28 * 28], name='input')\n",
    "\n",
    "# desired output (ie real labels)\n",
    "d = tf.placeholder(tf.int32, [None, 1], name='labels')\n",
    "# one-hot encoding produces a vecor of shape (batch, 1, 10) instead of (batch, 10)\n",
    "d_1_hot = tf.squeeze(tf.one_hot(d, 10), axis=1)\n",
    "\n",
    "# computed output of the network without activation\n",
    "y = tf.matmul(x, W) + b\n",
    "\n",
    "# loss function\n",
    "cross_entropy      = tf.nn.softmax_cross_entropy_with_logits(logits = y, labels = d_1_hot)\n",
    "mean_cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "# The optimizer should minimize the cross_entropy.\n",
    "optimizer          = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)#0.5)\n",
    "training_step      = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 + 7\n",
    "Now we are training the network and store all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from our loader.\n",
    "d_train, l_train, d_test, l_test = (mnist._training_data, mnist._training_labels, mnist._test_data, mnist._test_labels)\n",
    "\n",
    "# The data comes in image format, which we flatten\n",
    "d_test  = np.reshape(d_test, (-1, 28 * 28))\n",
    "d_train = np.reshape(d_train, (-1, 28 * 28))\n",
    "\n",
    "# The labels only have 1 dimensions, we need to blow it up to 2\n",
    "l_test  = l_test[:, np.newaxis]\n",
    "l_train = l_train[:, np.newaxis]\n",
    "\n",
    "# check if neuron firing strongest coincides with max value position in real labels\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(d_1_hot, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# record accuracy\n",
    "training_step_accuracy = []\n",
    "test_step_accuracy     = []\n",
    "\n",
    "# record cross-entropy\n",
    "training_step_entropy = []\n",
    "test_step_entropy     = []\n",
    "\n",
    "# record weights\n",
    "weights = []\n",
    "\n",
    "# Specify number of epochs and the batch size\n",
    "n_epochs   = 3\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    i = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        print('Epoch %d' % epoch)\n",
    "        for mb, labels in mnist._get_batch(d_train, l_train, batch_size):\n",
    "            values = sess.run({'weights': W, 'step': training_step}, feed_dict={x: mb, d: labels})\n",
    "            if i % 10 == 0:\n",
    "                current_train_accuracy = sess.run(accuracy, feed_dict={x: d_train, d: l_train})\n",
    "                current_test_accuracy = sess.run(accuracy, feed_dict={x: d_test, d: l_test})\n",
    "                training_step_accuracy.append(current_train_accuracy)\n",
    "                test_step_accuracy.append(current_test_accuracy)\n",
    "\n",
    "                current_train_entropy = sess.run(mean_cross_entropy, feed_dict={x: d_train, d: l_train})\n",
    "                current_test_entropy = sess.run(mean_cross_entropy, feed_dict={x: d_test, d: l_test})\n",
    "                training_step_entropy.append(current_train_entropy)\n",
    "                test_step_entropy.append(current_test_entropy)\n",
    "\n",
    "                weights.append(np.reshape(values['weights'], (28, 28, 10)))\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Monitor the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Problem: We append the accuray every 10th step, so we may miss the last one\n",
    "print('(Almost) final test accuracy: %f' % test_step_accuracy[-1])\n",
    "\n",
    "# Plot entropy and accuray\n",
    "f = plt.figure()\n",
    "ax_acc = f.add_subplot(121)\n",
    "ax_acc.set_title('Accuracy over training and test sets')\n",
    "ax_acc.set_xlabel('(n*10)th batch')\n",
    "ax_acc.set_ylabel('Accuracy')\n",
    "ax_acc.plot(test_step_accuracy, linestyle=':', label='Test set')\n",
    "ax_acc.plot(training_step_accuracy, linestyle=':', label='Training set')\n",
    "ax_acc.legend()\n",
    "\n",
    "ax_entropy = f.add_subplot(122)\n",
    "ax_entropy.set_title('Cross Entropy over training and test sets')\n",
    "ax_entropy.set_xlabel('(n*10)th batch')\n",
    "ax_entropy.set_ylabel('Cross Entropy')\n",
    "ax_entropy.plot(test_step_entropy, linestyle=':', label='Test set')\n",
    "ax_entropy.plot(training_step_entropy, linestyle=':', label='Training set')\n",
    "ax_entropy.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot weights interactively\n",
    "rows, cols = (2, 5)\n",
    "f2, axarr = plt.subplots(rows, cols)\n",
    "plt.ion()\n",
    "for row in range(2):\n",
    "    for col in range(5):\n",
    "        ax = axarr[row][col]\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    current_weights = weights[i]\n",
    "    for row in range(2):\n",
    "        for col in range(5):\n",
    "            f2.suptitle('Step %d of %d' % (i, len(weights)))\n",
    "            ax = axarr[row][col]\n",
    "            ax.cla()\n",
    "            index = row * rows + col\n",
    "            ax.set_title('Neuron %d' % index)\n",
    "            # there's many diverging cmaps\n",
    "            # (https://matplotlib.org/examples/color/colormaps_reference.html)\n",
    "            ax.imshow(current_weights[..., index], cmap='Spectral')\n",
    "\n",
    "    # pause so that it always takes 5 seconds\n",
    "    # Note: The animation seems to slow down linearly, unless we clear the\n",
    "    # axes (see above).\n",
    "    # Uncomment this function if you have pyplot > v2.11. Details:\n",
    "    #     https://stackoverflow.com/questions/46982150/matplotlib-pyplot-global-name-time-is-not-defined-error\n",
    "    #plt.pause(5 / len(weights)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}